{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Iowa Housing Prices Using the Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = 'home-data/train.csv'\n",
    "home_data = pd.read_csv(iowa_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a target object and call it 'y' and X that contains the features that we want to consider in building our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             LotArea    YearBuilt     1stFlrSF     2ndFlrSF     FullBath  \\\n",
      "count    1460.000000  1460.000000  1460.000000  1460.000000  1460.000000   \n",
      "mean    10516.828082  1971.267808  1162.626712   346.992466     1.565068   \n",
      "std      9981.264932    30.202904   386.587738   436.528436     0.550916   \n",
      "min      1300.000000  1872.000000   334.000000     0.000000     0.000000   \n",
      "25%      7553.500000  1954.000000   882.000000     0.000000     1.000000   \n",
      "50%      9478.500000  1973.000000  1087.000000     0.000000     2.000000   \n",
      "75%     11601.500000  2000.000000  1391.250000   728.000000     2.000000   \n",
      "max    215245.000000  2010.000000  4692.000000  2065.000000     3.000000   \n",
      "\n",
      "       BedroomAbvGr  TotRmsAbvGrd  \n",
      "count   1460.000000   1460.000000  \n",
      "mean       2.866438      6.517808  \n",
      "std        0.815778      1.625393  \n",
      "min        0.000000      2.000000  \n",
      "25%        2.000000      5.000000  \n",
      "50%        3.000000      6.000000  \n",
      "75%        3.000000      7.000000  \n",
      "max        8.000000     14.000000  \n"
     ]
    }
   ],
   "source": [
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt','1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's split our dataset into validation and training data using train_test_split. Afterwards, we can now build our model by specifiying what kind of ML algorithm we want to employ. For this case, we will use DecisionTreeRegressor to build our model based on the Decision Tree learning method.\n",
    "\n",
    "### After building, we will feed our training dataset to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "Validation MAE (in dollars): 29,653\n"
     ]
    }
   ],
   "source": [
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"\\n \\nValidation MAE (in dollars): {:,.0f}\".format(val_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can still further optimize this model by finding the ideal max_leaf_nodes. But first, let's create a function to get the Mean Absolute Error to make things more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes,random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    predicted_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, predicted_val)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 35044.51299744237,\n",
      " 25: 29016.41319191076,\n",
      " 50: 27405.930473214907,\n",
      " 100: 27282.50803885739,\n",
      " 250: 27893.822225701646,\n",
      " 500: 29454.18598068598}\n",
      "\n",
      " The optimal number of max_leaf_nodes is:  100\n"
     ]
    }
   ],
   "source": [
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "\n",
    "# explicit loop\n",
    "scores = {max_leaf_nodes: get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y) for max_leaf_nodes in candidate_max_leaf_nodes}\n",
    "best_tree_size = min(scores, key=scores.get)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print('\\n The optimal number of max_leaf_nodes is: ',best_tree_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we've determined the optimal number of max_leaf_nodes, we can fine tune our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=100, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tune the model\n",
    "\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)\n",
    "\n",
    "# fit the final model and uncomment the next two lines\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
